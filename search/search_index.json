{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Ferramenta de Gerenciamento do Amazon S3","text":"<p>Esta \u00e9 uma ferramenta/produto de gerenciamento de buckets S3, instancias de armazenamento, com templates terraform tipo como se fosse um \"google drive\". </p> <p>Com esta ferramenta, ser\u00e1  poss\u00edvel criar-se novos buckets no S3, gerenciar suas permiss\u00f5es de acesso, cria\u00e7\u00e3o de folders, cria\u00e7\u00e3o de pol\u00edticas. Ser\u00e1 poss\u00edvel tamb\u00e9m a listagem de buckets na conta do usu\u00e1rios, objetos em um bucket especificado, configura\u00e7\u00f5es de lifecycle. </p> <p>Por fim, pretende-se a cria\u00e7\u00e3o de uma simples interface web que possibilite o upload de objetos no bucket, assim como listagem,  download e exclus\u00e3o destes caso seja do desejo do usu\u00e1rio. Notifica\u00e7\u00e3o para saber qual bucket foi modificado.</p>"},{"location":"#pre-requisitos","title":"Pr\u00e9 requisitos","text":"<p>Para execu\u00e7\u00e3o adequada deste roteiro, s\u00e3o necess\u00e1rios os seguintes pr\u00e9-requisitos:</p> <ul> <li>Ubuntu &gt; 20.0 ou WSL2</li> <li>Terraform</li> <li>Python &gt; 3.6</li> <li>Conta na AWS com usu\u00e1rio com permiss\u00f5es de administrador</li> </ul>"},{"location":"#recursos-essenciais-da-ferramenta","title":"Recursos essenciais da ferramenta","text":"<p>Queremos, ao fim desse roteiro, provisionar uma arquitetura como a abaixo:</p> <p>Que ser\u00e1 capaz de criar um sistema de armazenamento de arquivos e at\u00e9 site est\u00e1tico, com funcionalidade de gerar notifica\u00e7\u00f5es ao dono desses recursos para cada objeto adicionado nos buckets, criando assim al\u00e9m de grande disponibilidade e facilidade de uso, uma arquitetura altamente rastre\u00e1vel, permitindo a verifica\u00e7\u00e3o mais r\u00e1pido de erros e brechas de seguran\u00e7a.</p>"},{"location":"#aws","title":"AWS","text":"<p>\u00c9 uma plataforma de servi\u00e7os de computa\u00e7\u00e3o em nuvem oferecida pela Amazon, que permite que indiv\u00edduos e organiza\u00e7\u00f5es implementem aplicativos, servi\u00e7os e infraestrutura na nuvem. A AWS oferece uma ampla variedade de servi\u00e7os em nuvem, incluindo computa\u00e7\u00e3o, armazentamento, banco de dados, an\u00e1lise, intelig\u00eancia artificial, machine learning e muito mais.</p> <p>Para conseguir interagir com os servi\u00e7os e fun\u00e7\u00f5es que a AWS prov\u00e9m, por meio de IaC (Infrastructure as Code), \u00e9 necess\u00e1rio obter chaves de acesso, que permitam o gerenciamento e provisionamento dos recursos que desejamos alocar na nuvem.</p> <p>De posse de suas respectivas chaves de acesso, crie duas vari\u00e1veis de ambiente, conforme padr\u00e3o abaixo:</p> <p><pre><code>export AWS_ACCESS_KEY_ID=&lt;ID_CHAVE_DE_ACESSO&gt;\nexport AWS_SECRET_ACCESS_KEY=&lt;CHAVE_SECRETA_DE_ACESSO&gt;\n</code></pre> Realiza-se o acesso a essas chaves para seguran\u00e7a de dados de quem acessa, pois assim evita-se sempre ter que colocar a senha no ambiente e a senha estar exposta</p>"},{"location":"#s3","title":"S3","text":"<p>\u00c9 um servi\u00e7o de armanezamento de objetos oferecido pela Amazon Web Services (AWS). O S3 permite que os usu\u00e1rios armazenem e recuperem arquivos de qualquer lugar da web. O S3 \u00e9 amplamente utilizado por empresas e organiza\u00e7\u00f5es de diferentes setores para armazenamento e compartilhamento de arquivos, backup e arquivamento de dados, hospedagem de sites e aplicativos, e muito mais.</p>"},{"location":"#bucket","title":"Bucket","text":"<p>Bucket \u00e9 um conceito de armazenamento usado em servi\u00e7os de armazenamento em nuvem, como o Amazon S3. Um bucket pode ser considerado como um cont\u00eainer de objetos, que pode armazenar e gerenciar v\u00e1rios objetos, como arquivos, imagens, v\u00eddeos, entre outros. Os buckets s\u00e3o amplamente utilizados para hospedar sites est\u00e1ticos, armazenamento de backup, arquivamento de dados e muito mais. Eles s\u00e3o uma parte essencial de muitos servi\u00e7os em nuvem e permitem que os usu\u00e1rios armazenem, gerenciem e acessem dados de qualquer lugar da web.</p>"},{"location":"#terraform","title":"Terraform","text":"<p>\u00c9 uma infraestrutura que descreve os recursos que voc\u00ea deseja provisionar, como servidores, banco de dados e outros. Al\u00e9m disso, voc\u00ea pode usar o Terraform para criar, alterar e destruir recursos automaticamente.</p>"},{"location":"#s3-events","title":"S3 Events","text":"<p>O Amazon S3 Events permite que voc\u00ea monitore altera\u00e7\u00f5es em seu bucket do Amazon S3 e responda essas altera\u00e7\u00f5es executando a\u00e7\u00f5es autom\u00e1ticas. Quando um evento ocorre em seu bucket como upload de um arquivo ou a exclus\u00e3o de um objeto o S3 Events pode acusar uma a\u00e7\u00e3o autom\u00e1tica como a invoca\u00e7\u00e3o de uma fun\u00e7\u00e3o AWS Lambda ou a notifica\u00e7\u00e3o de um t\u00f3pico do Amazon Simple Notificacion Service (SNS).</p>"},{"location":"#funcao-aws-lambda","title":"Fun\u00e7\u00e3o AWS Lambda","text":"<p>As Fun\u00e7\u00f5es AWS Lambda fazem o processamento de eventos em tempo real como logs e notifica\u00e7\u00f5es. Por exemplo, voc\u00ea pode criar uma fun\u00e7\u00e3o lambda que \u00e9 acionada sempre que um novo objeto \u00e9 enviado para um bucket do Amazon S3. A fun\u00e7\u00e3o pode processar o objeto, extrair informa\u00e7\u00f5es relevantes, executar transforma\u00e7\u00f5es ou armazenar dados em outros servi\u00e7o. </p>"},{"location":"#amazon-simple-notification-service-sns","title":"Amazon Simple Notification Service (SNS)","text":"<p>O SNS \u00e9 um servi\u00e7o de mensagens e notifica\u00e7\u00e3o da AWS que permite enviar mensagens para diferentes tipos de endpoints como emails, mensagens de texto(SMS), URLs entre outros. Al\u00e9m disso, voc\u00ea pode configurar o acesso para quem pode publicar e para quem pode se inscrever no t\u00f3pico.</p>"},{"location":"#cloudwatch-alarm","title":"CloudWatch Alarm","text":"<p>O CloudWatch Alarm \u00e9 um servi\u00e7o de monitoramento e observabilidade da AWS. O CloudWatch Alarm permite monitorar m\u00e9tricas espec\u00edficas e acionar a\u00e7\u00f5es autom\u00e1ticas com base em condi\u00e7\u00f5es predefinidas.</p>"},{"location":"#iniciando-nossa-infraestrutura","title":"Iniciando nossa infraestrutura","text":"<p>Crie uma pasta para organizar nossos arquivos chamada terraform/::</p> <pre><code>mkdir terraform cd terraform\n</code></pre> <p>Como nosso primeiro objetivo \u00e9 criar um bucket na AWS crie um template chamado s3.tf com o seguinte conte\u00fado:</p> s3.tf<pre><code>#Provider and default region used\nprovider \"aws\" {\nregion     = \"us-east-2\"\n}\nresource \"aws_s3_bucket\" \"exemplo\" {\nbucket = \"&lt;Nome do bucket&gt;\"\ntags = {\nName        = \"My bucket\"\nEnvironment = \"Dev\"\n}\n}\n</code></pre> <p> Subistitua o nome do bucket pelo que voc\u00ea deseja, lembrando que esse nome \u00e9 \u00fanico em toda AWS</p> <p>Inicie ent\u00e3o os recursos terraform necess\u00e1rios para provisionar rodando o comando abaixo:</p> <pre><code>terraform init\n</code></pre> <p>Agora veremos o plano de cria\u00e7\u00e3o desses recursos:</p> <pre><code>terraform plan\n</code></pre> <p>Por fim, realize deploy deste recurso na nuvem:</p> <pre><code>terraform apply -auto-approve\n</code></pre> <p>Caso tudo d\u00ea certo voc\u00ea ver\u00e1 isso no console da AWS</p>"},{"location":"#como-subir-um-site-estatico-por-terraform","title":"Como subir um site est\u00e1tico por Terraform","text":"<p>Agora que j\u00e1 conseguimos subir um bucket privado de uso geral, podemos tamb\u00e9m modificar nossa infraestrutura para provisionar buckets que disponibilizem p\u00e1ginas est\u00e1ticas, conforme nosso plano de infraestrutura. Para isso, devemos...</p> <ul> <li>Fazer um provedor de nuvem da AWS</li> <li>Especificar o recurso que se quer criar : um bucket</li> <li>Define-se os controles do bucket</li> <li>Definir os acesso publico pra tirar esse bloqueio do </li> <li>Definir qual o acesso do bucket</li> <li>Definir uma nova configura\u00e7\u00e3o de bucket</li> <li>Pol\u00edtica de acesso a leitura do bucket</li> <li>Configura\u00e7\u00f5es e buckets de indexar pagina </li> </ul> <p>Para isso, crie um novo arquivo chamado s3_website, que ir\u00e1 realizar os passos acima:</p> s3_website.tf<pre><code>provider \"aws\" {\nregion = \"us-east-1\" # Substitua pela regi\u00e3o desejada\n}\nresource \"aws_s3_bucket\" \"website\" {\nbucket = \"bucketdanivinhaprojeto21\"\n}\nresource \"aws_s3_bucket_ownership_controls\" \"example\" {\nbucket = aws_s3_bucket.website.id\nrule {\nobject_ownership = \"BucketOwnerPreferred\"\n}\n}\nresource \"aws_s3_bucket_public_access_block\" \"example\" {\nbucket = aws_s3_bucket.website.id\nblock_public_acls       = false\nblock_public_policy     = false\nignore_public_acls      = false\nrestrict_public_buckets = false\n}\nresource \"aws_s3_bucket_acl\" \"example\" {\ndepends_on = [\naws_s3_bucket_ownership_controls.example,\naws_s3_bucket_public_access_block.example,\n]\nbucket = aws_s3_bucket.website.id\nacl    = \"public-read\"\n}\nresource \"aws_s3_bucket_versioning\" \"website\" {\nbucket = aws_s3_bucket.website.id\nversioning_configuration {\nstatus = \"Enabled\"\n}\n}\ndata \"aws_caller_identity\" \"current\" {}\nresource \"aws_s3_bucket_policy\" \"public_read_access\" {\nbucket = aws_s3_bucket.website.id\npolicy = data.aws_iam_policy_document.public_read_access.json\n}\ndata \"aws_iam_policy_document\" \"public_read_access\" {\nstatement {\nprincipals {\ntype = \"*\"\nidentifiers = [\"*\"]\n}\nactions = [\n\"s3:GetObject\",\n\"s3:ListBucket\",\n]\nresources = [\naws_s3_bucket.website.arn,\n\"${aws_s3_bucket.website.arn}/*\",\n]\n}\n}\nresource \"aws_s3_bucket_website_configuration\" \"website\" {\nbucket = aws_s3_bucket.website.bucket\nindex_document {\nsuffix = \"index.html\"\n}\n}\nresource \"aws_s3_object\" \"index_page\" {\nbucket       = aws_s3_bucket.website.id\nkey          = \"index.html\"\ncontent_type = \"text/html; charset=UTF-8\"\nsource       = \"index.html\"\n} </code></pre> <p>Na mesma pasta crie um arquivo chamado index.html e coloque o seguinte conte\u00fado nele:</p> <pre><code>&lt;h1&gt;Hello World&lt;/h1&gt;\n</code></pre> <p>Inicie ent\u00e3o os recursos terraform necess\u00e1rios para provisionar rodando o comando abaixo:</p> <pre><code>terraform init\n</code></pre> <p>Agora veremos o plano de cria\u00e7\u00e3o desses recursos:</p> <pre><code>terraform plan\n</code></pre> <p>Por fim, realize deploy deste recurso na nuvem:</p> <pre><code>terraform apply -auto-approve\n</code></pre> <p>Caso tudo d\u00ea certo voc\u00ea ver\u00e1 isso no console da AWS</p> <p>E a pagina voc\u00ea ver\u00e1 isso</p> <p>Fica disponibilizado o link em que voc\u00ea pode verificar:</p> <pre><code>http://bucketdanivinhaprojeto21.s3-website-us-east-1.amazonaws.com\n</code></pre>"},{"location":"#s3-events-engatilhando-uma-funcao-lambda","title":"S3 events engatilhando uma fun\u00e7\u00e3o Lambda","text":"<p>J\u00e1 conseguimos criar diferentes buckets que contemplam sua fun\u00e7\u00e3o: </p> <p>Armazenar objetos</p> <p>Para se adequar a nossa arquitetura desejada, devemos ent\u00e3o integrar o S3 events, um notificador de eventos pr\u00f3prio do Amazon S3 para engatilhar uma fun\u00e7\u00e3o Lambda a cada vez que um novo objeto for adicionado neste bucket.</p> <p>Para isso, precisamos ent\u00e3o:</p> <ul> <li>Configurar S3 events nos buckets que j\u00e1 possu\u00edmos;</li> <li>Criar um template que provisiona uma fun\u00e7\u00e3o Lambda que ser\u00e1 engatilhada por esse evento</li> <li>Criar permiss\u00f5es que autorizem o S3 events a engatilhar a fun\u00e7\u00e3o.</li> </ul> <p>Para isso, iremos utilizar m\u00f3dulos do terraform, para melhorar a organiza\u00e7\u00e3o de nossos templates e tamb\u00e9m facilitar a conex\u00e3o entre esses templates, conforme ser\u00e1 necess\u00e1rio.</p> <p>Crie tr\u00eas pastas, chamadas respectivamente lambda, s3 e s3_website:</p> <pre><code>mkdir lambda\nmkdir s3\nmkdir s3_website\n</code></pre> <p>Mova o arquivo s3.tf para a pasta s3/, s3_website.tf para s3_website/ e crie um arquivo lambda.tf para a pasta lambda/. N\u00e3o coloque nada nesse arquivo ainda.</p> <p>Modifique o arquivo s3.tf, adicionando os componentes de permiss\u00e3o para a execu\u00e7\u00e3o da Lambda e notifica\u00e7\u00e3o do S3.</p> s3.tf<pre><code>variable \"function_name\" {\ntype = string\n}\nvariable \"function_arn\" {\ntype = string\n}\nresource \"aws_s3_bucket\" \"exemplo\" {\nbucket = \"bucket-nivea-456864\"\ntags = {\nName        = \"My bucket\"\nEnvironment = \"Dev\"\n}\n}\nresource \"aws_lambda_permission\" \"exemplo\" {\nstatement_id  = \"example-statement-id\"\naction        = \"lambda:InvokeFunction\"\nfunction_name =  var.function_name\nprincipal     = \"s3.amazonaws.com\"\nsource_arn    = \"${aws_s3_bucket.exemplo.arn}/\"\n}\nmodule \"s3_notification\" {\nsource  = \"terraform-aws-modules/s3-bucket/aws//modules/notification\"\nversion = \"~&gt; 3.0\"\nbucket = aws_s3_bucket.exemplo.id\neventbridge = true\nlambda_notifications = {\nlambda = {\nfunction_arn  = var.function_arn\nfunction_name = var.function_name\nevents        = [\"s3:ObjectCreated:*\"]\n}\n}\n}\n</code></pre> <p>Dentro da pasta lambda/, crie um arquivo chamado events.py, com o seguinte conte\u00fado:</p> events.py<pre><code>import json \ndef lambda_handler(event, context):\nprint(\"Novo objeto adicionado\")\nreturn {\n'statusCode': 200,\n'body': json.dumps('Hello from Lambda!')\n}\n</code></pre> <p>Compacte  fun\u00e7\u00e3o usando seu compactador preferido (Winrar, Zip e etc), para criar um arquivo chamado events.zip que contenha o arquivo events.py.</p> <p>Crie ent\u00e3o o arquivo lambda.tf na atual pasta, que ir\u00e1 criar:</p> <ul> <li>A fun\u00e7\u00e3o propriamente dita, com sua linguagem de programa\u00e7\u00e3o, nome e outras configura\u00e7\u00f5es;</li> <li>Role com permiss\u00f5es necess\u00e1rias;</li> <li>Pol\u00edticas de permiss\u00f5es necess\u00e1rias;</li> <li>Output para passar detalhes da fun\u00e7\u00e3o para o template do S3.</li> </ul> <p>Assim crie:</p> lambda.tf<pre><code>resource \"aws_lambda_function\" \"example\" {\nfunction_name = \"events\"\nruntime = \"python3.8\"\nhandler = \"events.lambda_handler\"\nrole = aws_iam_role.lambda.arn\nfilename = \"lambda/events.zip\"\nenvironment {\nvariables = {\nEXAMPLE_VARIABLE = \"example_value\"\n}\n}\n}\nresource \"aws_iam_role\" \"lambda\" {\nname = \"a1s3-events-execution-lambda\"\nassume_role_policy = jsonencode({\nVersion = \"2012-10-17\"\nStatement = [\n{\nAction = \"sts:AssumeRole\"\nEffect = \"Allow\"\nPrincipal = {\nService = \"lambda.amazonaws.com\"\n}\n}\n]\n})\n}\nresource \"aws_iam_role_policy_attachment\" \"lambda\" {\npolicy_arn = \"arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole\"\nrole       = aws_iam_role.lambda.name\n}\noutput \"function_name\" {\nvalue = aws_lambda_function.example.function_name\n}\noutput \"function_arn\" {\nvalue = aws_lambda_function.example.arn\n}\n</code></pre> <p>Retorne para o diret\u00f3rio terraform/: <pre><code>cd ..\n</code></pre></p> <p>Crie um arquivo main.tf, que ir\u00e1 reunir e referenciar os m\u00f3dulos agora criados:</p> <ul> <li>M\u00f3dulo Lambda e seus outputs(nome e ARN);</li> <li>M\u00f3dulo S3;</li> <li>M\u00f3dulo S3-Website</li> </ul> main.tf<pre><code>provider \"aws\" {\nregion     = \"us-east-1\"\n}\nmodule \"lambda\" {\nsource = \"./lambda\"\n}\noutput \"function_name\" {\nvalue = module.lambda.function_name\n}\noutput \"function_arn\" {\nvalue = module.lambda.function_arn\n}\nmodule \"s3\" {\nsource = \"./s3\"\nfunction_name = module.lambda.function_name\nfunction_arn = module.lambda.function_arn\n}\nmodule \"website\" {\nsource = \"./s3_website\"\n}\n</code></pre> <p>Dessa forma sua organiza\u00e7\u00e3o de diret\u00f3rio deve ficar assim:</p> <pre><code>terraform/\n  |\n  ------main.tf\n  |\n  ------lambda/\n      |\n      ------lambda.tf\n  |\n  ------s3/\n      |\n      ------s3.tf\n  |\n  ------s3_website/\n      |\n      ------s3_website.tf\n</code></pre> <p>Rode em seu terminal para iniciar novamente o backend:</p> <pre><code>terraform init\n</code></pre> <p>Veja se o acoplamento l\u00f3gico dos componentes est\u00e1 correto:</p> <pre><code>terraform plan\n</code></pre> <p>Aplique as mudan\u00e7as:</p> <p><pre><code>terraform apply -auto-approve\n</code></pre> Estando tudo correto, voc\u00ea dever\u00e1 em seu console, al\u00e9m dos buckets anteriormente criados, a seguinte fun\u00e7\u00e3o:</p>"},{"location":"#criando-um-topico-de-notificacoes-no-sns","title":"Criando um t\u00f3pico de notifica\u00e7\u00f5es no SNS","text":"<p>At\u00e9 ent\u00e3o conseguimos provisionar um bucket e uma fun\u00e7\u00e3o Lambda engatilhada a cada novo objeto adicionado neste bucket.  Precisamos ent\u00e3o, criar uma notifica\u00e7\u00e3o que avise algum dos desenvolvedores ou dono da infraestrutura, que um novo objeto foi adicionado, gerando assim, maior controle da infraestrutura e suas mudan\u00e7as.</p> <p>Dessa forma, iremos utilizar o SNS, que conforme explicado no come\u00e7o deste roteiro, tem por seu fim, enviar notifica\u00e7\u00f5es para diferentes meios, como email, SMS, HTTP e outros. Para este projeto, iremos configurar um t\u00f3pico SNS que ir\u00e1 enviar uma solicita\u00e7\u00e3o par um email cadastrado.</p> <p>Dessa forma, crie uma pasta chamada SNS/ dentro do diret\u00f3rio terraform/, e adicione o arquivo sns.tf.</p> <p>Este ir\u00e1 conter:</p> <ul> <li>O nome do t\u00f3pico a ser criado;</li> <li>O protocolo de envio do t\u00f3pico (email) e a endpoit de envio (seu endere\u00e7o de email);</li> <li>E um output do ARN do recurso criado para uso posterior.</li> </ul> <p>Assim, coloque no arquivo sns.tf:</p> sns.tf<pre><code>resource \"aws_sns_topic\" \"example_topic\" {\nname = \"example-topic\"\n}\nvariable \"email_subscription\" {\ntype    = string\ndefault = \"teste@al.insper.edu.br\" # Insira seu email\n}\nresource \"aws_sns_topic_subscription\" \"email_subscription\" {\ntopic_arn = aws_sns_topic.example_topic.arn\nprotocol  = \"email\"\nendpoint  = var.email_subscription\n}\noutput \"sns_arn\" {\nvalue = aws_sns_topic.example_topic.arn\n}\n</code></pre> <p>Dessa forma sua organiza\u00e7\u00e3o de diret\u00f3rio deve ficar assim:</p> <pre><code>terraform/\n  |\n  ------main.tf\n  |\n  ------lambda/\n      |\n      ------lambda.tf\n  |\n  ------sns/\n      |\n      ------sns.tf\n  |\n  ------s3/\n      |\n      ------s3.tf\n  |\n  ------s3_website/\n      |\n      ------s3_website.tf\n</code></pre> <p>Retorne para o diret\u00f3rio terraform/ e adeque seu arquivo main.tf para conter o m\u00f3dulo sns/:</p> main.tf<pre><code>provider \"aws\" {\nregion     = \"us-east-1\"\n}\nmodule \"lambda\" {\nsource = \"./lambda\"\n}\noutput \"function_name\" {\nvalue = module.lambda.function_name\n}\noutput \"function_arn\" {\nvalue = module.lambda.function_arn\n}\nmodule \"s3\" {\nsource = \"./s3\"\nfunction_name = module.lambda.function_name\nfunction_arn = module.lambda.function_arn\n}\nmodule \"website\" {\nsource = \"./s3_website\"\n}\nmodule \"sns\" {\nsource = \"./sns\"\n}\noutput \"sns_arn\" {\nvalue = module.sns.sns_arn\n}\n</code></pre> <p>Rode em seu terminal para iniciar novamente o backend:</p> <pre><code>terraform init\n</code></pre> <p>Veja se o acoplamento l\u00f3gico dos componentes est\u00e1 correto:</p> <pre><code>terraform plan\n</code></pre> <p>Aplique as mudan\u00e7as:</p> <p><pre><code>terraform apply -auto-approve\n</code></pre> Estando tudo correto, voc\u00ea dever\u00e1 em seu console, o t\u00f3pico criado:</p>"},{"location":"#criando-um-alarme-no-cloudwatch","title":"Criando um alarme no Cloudwatch","text":"<p>J\u00e1 conseguimos ent\u00e3o ter uma fun\u00e7\u00e3o Lambda que \u00e9 engatilhada a cada novo objeto colocado em um bucket e um t\u00f3pico no SNS que consegue gerar notifica\u00e7\u00f5es de email para o usu\u00e1rio cadastrado.</p> <p>Precisamos ent\u00e3o criar um componente que ir\u00e1 ser o conector entre estes, isto \u00e9, a cada vez que uma fun\u00e7\u00e3o Lambda for engatilhada, gerar uma notifica\u00e7\u00e3o para o usu\u00e1rio via SNS.</p> <p>Para isso, podemos criar um alarme no Cloudwatch que ir\u00e1 monitorar os logs padr\u00f5es gerados pela Lambda, e com isso, gera uma notifica\u00e7\u00e3o no t\u00f3pico.</p> <p>Dessa forma, devemos criar um alarme que:</p> <ul> <li>Receber\u00e1 o ARN do t\u00f3pico que ir\u00e1 gerar a notifica\u00e7\u00e3o;</li> <li>Ir\u00e1 filtrar nos logs da fun\u00e7\u00e3o Lambda desejada (aqui por padr\u00e3o chamada de events);</li> <li>Criar um alarme no Cloudwatch que ir\u00e1 transicionar do estado OK para ALARM a cada novo log ir\u00e1 tomar a a\u00e7\u00e3o de criar uma notifica\u00e7\u00e3o no t\u00f3pico que o ARN for passado ao template.</li> </ul> <p>Crie um arquivo chamado cloudwatch.tf em uma pasta chamada cloudwatch/ dentro do diret\u00f3rio terraform/:</p> <pre><code>mkdir cloudwatch\n</code></pre> <p>Coloque o arquivo da seguinte maneira:</p> <p>cloudwatch.tf<pre><code>variable \"sns_arn\" {\ntype = string\n}\nresource \"aws_cloudwatch_log_metric_filter\" \"lambda_log_filter\" {\nname           = \"lambda-log-filter\"\npattern        = \"{ $.eventType = Error }\" # Substitua pelo padr\u00e3o que voc\u00ea deseja monitorar\nlog_group_name = \"/aws/lambda/events\"      # Substitua pelo nome do grupo de log correto\nmetric_transformation {\nname        = \"ErrorCount\"\nnamespace   = \"Custom/CloudWatchLogs\"\nvalue       = \"1\"\ndefault_value = \"0\"\n}\n}\nresource \"aws_cloudwatch_metric_alarm\" \"lambda_log_alarm\" {\nalarm_name          = \"lambda-log-alarm\"\nalarm_description   = \"Alarm triggered on CloudWatch Logs\"\ncomparison_operator = \"GreaterThanOrEqualToThreshold\"\nevaluation_periods  = \"1\"\nmetric_name         = \"ErrorCount\"\nnamespace           = \"Custom/CloudWatchLogs\"\nperiod              = \"60\"\nstatistic           = \"SampleCount\"\nthreshold           = \"1\"\nalarm_actions       = [var.sns_arn]\ntreat_missing_data  = \"missing\"\n}\nresource \"aws_cloudwatch_log_metric_filter\" \"lambda_log_filter_subscription\" {\nname           = \"lambda-log-filter-subscription\"\npattern        = \"{ $.eventType = Error }\" # Substitua pelo padr\u00e3o que voc\u00ea deseja monitorar\nlog_group_name = \"/aws/lambda/events\"      # Substitua pelo nome do grupo de log correto\nmetric_transformation {\nname      = \"ErrorCountSubscription\"\nnamespace = \"Custom/CloudWatchLogs\"\nvalue     = \"1\"\n}\n}\n</code></pre> Dessa forma sua organiza\u00e7\u00e3o de diret\u00f3rio deve ficar assim:</p> <pre><code>terraform/\n  |\n  ------main.tf\n  |\n  ------lambda/\n      |\n      ------lambda.tf\n  |\n  ------sns/\n      |\n      ------sns.tf\n  |\n  ------s3/\n      |\n      ------s3.tf\n  |\n  ------s3_website/\n      |\n      ------s3_website.tf\n  |\n  ------cloudwatch/\n    |\n    ------cloudwatch.tf\n</code></pre> <p>Modifique o arquivo main.tf, para adequar o m\u00f3dulo rec\u00e9m criado:</p> <p>Veja que passamos o ARN do t\u00f3pico do SNS criado como uma vari\u00e1vel para o Cloudwatch Alarme.</p> main.tf<pre><code>provider \"aws\" {\nregion     = \"us-east-1\"\n}\nmodule \"lambda\" {\nsource = \"./lambda\"\n}\noutput \"function_name\" {\nvalue = module.lambda.function_name\n}\noutput \"function_arn\" {\nvalue = module.lambda.function_arn\n}\nmodule \"s3\" {\nsource = \"./s3\"\nfunction_name = module.lambda.function_name\nfunction_arn = module.lambda.function_arn\n}\nmodule \"website\" {\nsource = \"./s3_website\"\n}\nmodule \"sns\" {\nsource = \"./sns\"\n}\noutput \"sns_arn\" {\nvalue = module.sns.sns_arn\n}\nmodule \"cloudwatch\" {\nsource = \"./cloudwatch\"\nsns_arn = module.sns.sns_arn\n}\n</code></pre> <p>Rode em seu terminal para iniciar novamente o backend:</p> <pre><code>terraform init\n</code></pre> <p>Veja se o acoplamento l\u00f3gico dos componentes est\u00e1 correto:</p> <pre><code>terraform plan\n</code></pre> <p>Aplique as mudan\u00e7as:</p> <p><pre><code>terraform apply -auto-approve\n</code></pre> Estando tudo correto, voc\u00ea dever\u00e1 em seu console, o alarme do Cloudwatch criado:</p> <p>Veja em seu email cadastrado que voc\u00ea deve ter recebido uma notifica\u00e7\u00e3o:</p> <p>Para testar o funcionamento da arquitetura, adicione um objeto qualquer ao Bucket S3 rec\u00e9m criado. Depois de alguns minutos voc\u00ea dever\u00e1 receber um email como o abaixo, indicando que o Alarme do CloudWatch Alarme foi acionado e um novo objeto foi adicionado no bucket.</p> <p>Cloudwatch notificando alarme:</p> <p>Email de notifica\u00e7\u00e3o:</p>"},{"location":"#criando-mais-um-bucket-e-passando-nomes-como-variaveis","title":"Criando mais um Bucket e passando nomes como vari\u00e1veis","text":"<p>Apesar de j\u00e1 conseguirmos ter um Bucket padr\u00e3o que engatilha notifica\u00e7\u00f5es em um email previamente cadastrado e um bucket pr\u00f3prio para hosteamento de sites est\u00e1ticos, nossa arquitetura desejada prev\u00ea a cria\u00e7\u00e3o de um outro bucket para simular a divis\u00e3o entre buckets.</p> <p>Al\u00e9m disso, seria ideal que conseguimos, no momento da cria\u00e7\u00e3o (terraform apply), os nomes dos buckets e o email de destino para notifica\u00e7\u00f5es, facilitando assim o controle de erros (advindos do nome \u00fanico de buckets) e mudan\u00e7a de valores desejados (ao inv\u00e9s de ter que modificar o template propriamente).</p> <p>Assim, devemos:</p> <ul> <li>Criar um outro bucket (genericamente destinado a fotos, mas pode ser utilizado para outros fins do usu\u00e1rio);</li> <li>Generalizar o nome dos buckets e do email cadastrado (permitindo estes serem passados como vari\u00e1veis no momento de deploy da arquitetura);</li> </ul> <p>Para isso, primeiramente, crie uma pasta dentro de terraform/ chamada (genericamente), de s3_fotos. Nesta pasta, crie um arquivo chamado s3_fotos.tf, onde iremos:</p> <ul> <li>Criar um bucket genericamente para fotos;</li> <li>Criar um evento de S3 events para este;</li> <li>Criar vari\u00e1veis que permitam a passagem de nomes (nome do bucket e valores da fun\u00e7\u00e3o Lambda associada) durante cria\u00e7\u00e3o (ou usar defaults);</li> </ul> <p>Assim, crie o arquivo da seguinte forma:</p> s3_fotos.tf<pre><code>variable \"function_name\" {\ntype = string\n}\nvariable \"function_arn\" {\ntype = string\n}\nvariable \"fotos_name\" {\ntype = string\ndefault = \"ProjetoBucket132\"\n}\nresource \"aws_s3_bucket\" \"exemplo_fotos\" {\nbucket = var.fotos_name\ncors_rule {\nallowed_origins = [\"*\"]\nallowed_methods = [\"GET\", \"PUT\", \"POST\", \"DELETE\"]\nallowed_headers = [\"*\"]\n}\ntags = {\nName        = \"My bucket\"\nEnvironment = \"Dev\"\n}\n}\nresource \"aws_lambda_permission\" \"exemplo_fotos\" {\nstatement_id  = \"fotos-statement-id\"\naction        = \"lambda:InvokeFunction\"\nfunction_name =  var.function_name\nprincipal     = \"s3.amazonaws.com\"\nsource_arn    = \"${aws_s3_bucket.exemplo_fotos.arn}/\"\n}\nmodule \"s3_notification\" {\nsource  = \"terraform-aws-modules/s3-bucket/aws//modules/notification\"\nversion = \"~&gt; 3.0\"\nbucket = aws_s3_bucket.exemplo_fotos.id\neventbridge = true\nlambda_notifications = {\nlambda = {\nfunction_arn  = var.function_arn\nfunction_name = var.function_name\nevents        = [\"s3:ObjectCreated:*\"]\n}\n}\n}\n</code></pre> <p>Dessa forma, nosso diret\u00f3rio ficar\u00e1 com a seguinte estrutura: <pre><code>terraform/\n  |\n  ------main.tf\n  |\n  ------lambda/\n      |\n      ------lambda.tf\n  |\n  ------sns/\n      |\n      ------sns.tf\n  |\n  ------s3_fotos/\n      |\n      ------s3_fotos.tf\n  |\n  ------s3/\n      |\n      ------s3.tf\n  |\n  ------s3_website/\n      |\n      ------s3_website.tf\n  |\n  ------cloudwatch/\n    |\n    ------cloudwatch.tf\n</code></pre></p> <p>Devemos agora ent\u00e3o, modificar em sequ\u00eancia:</p> <ul> <li>Adicionar um evento de S3 events para o bucket de Website;</li> <li>Criar vari\u00e1veis da fun\u00e7\u00e3o Lambda e nome do website no bucket de hosteamento;</li> <li>Criar vari\u00e1vel de nome do bucket para o Bucket principal;</li> <li>Criar vari\u00e1veis de nomes para os buckets e e de email e referenciar nos respectivos m\u00f3dulo no arquivo main.tf;</li> </ul> <p>Assim, altere e/ou adicione seu arquivo s3_website as seguintes linhas (adicionando as duas primeiras mudan\u00e7as citadas acima):</p> <p> Veja que o arquivo abaixo est\u00e1 incompleto para diminuir espa\u00e7o, n\u00e3o o copie apenas, e sim substitua/adicione as partes aqui ilustradas</p> <p>s3_website.tf<pre><code>variable \"function_name\" {\ntype = string\n}\nvariable \"function_arn\" {\ntype = string\n}\nvariable \"website_name\" {\ntype = string\ndefault = \"ProjetoBucket131\"\n}\nresource \"aws_s3_bucket\" \"website\" {\nbucket = var.website_name\ncors_rule {\nallowed_origins = [\"*\"]\nallowed_methods = [\"GET\", \"PUT\", \"POST\", \"DELETE\"]\nallowed_headers = [\"*\"]\n}\n}\n...\nresource \"aws_lambda_permission\" \"website\" {\nstatement_id  = \"website-statement-id\"\naction        = \"lambda:InvokeFunction\"\nfunction_name =  var.function_name\nprincipal     = \"s3.amazonaws.com\"\nsource_arn    = \"${aws_s3_bucket.website.arn}/\"\n}\nmodule \"s3_notification\" {\nsource  = \"terraform-aws-modules/s3-bucket/aws//modules/notification\"\nversion = \"~&gt; 3.0\"\nbucket = aws_s3_bucket.website.id\neventbridge = true\nlambda_notifications = {\nlambda = {\nfunction_arn  = var.function_arn\nfunction_name = var.function_name\nevents        = [\"s3:ObjectCreated:*\"]\n}\n}\n}\n</code></pre> Posteriormente, no arquivo s3_bucket.tf, adicione refer\u00eancias para a vari\u00e1vel de nome do bucket:</p> s3.tf<pre><code>variable \"function_name\" {\ntype = string\n}\nvariable \"function_arn\" {\ntype = string\n}\nvariable \"bucket_name\" {\ntype = string\ndefault = \"ProjetoBucket130\"\n}\nresource \"aws_s3_bucket\" \"exemplo\" {\nbucket = var.bucket_name\ncors_rule {\nallowed_origins = [\"*\"]\nallowed_methods = [\"GET\", \"PUT\", \"POST\", \"DELETE\"]\nallowed_headers = [\"*\"]\n}\ntags = {\nName        = \"My bucket\"\nEnvironment = \"Dev\"\n}\n}\nresource \"aws_lambda_permission\" \"exemplo\" {\nstatement_id  = \"documentos-statement-id\"\naction        = \"lambda:InvokeFunction\"\nfunction_name =  var.function_name\nprincipal     = \"s3.amazonaws.com\"\nsource_arn    = \"${aws_s3_bucket.exemplo.arn}/\"\n}\nmodule \"s3_notification\" {\nsource  = \"terraform-aws-modules/s3-bucket/aws//modules/notification\"\nversion = \"~&gt; 3.0\"\nbucket = aws_s3_bucket.exemplo.id\neventbridge = true\nlambda_notifications = {\nlambda = {\nfunction_arn  = var.function_arn\nfunction_name = var.function_name\nevents        = [\"s3:ObjectCreated:*\"]\n}\n}\n}\n</code></pre> <p>Por fim, no arquivo main.tf, crie as vari\u00e1veis necess\u00e1rias, e as repasse para seus respectivos m\u00f3dulos, conforme arquivo abaixo:</p> main.tf<pre><code>provider \"aws\" {\nregion     = \"us-east-1\"\n}\nmodule \"lambda\" {\nsource = \"./lambda\"\n}\noutput \"function_name\" {\nvalue = module.lambda.function_name\n}\noutput \"function_arn\" {\nvalue = module.lambda.function_arn\n}\nmodule \"s3\" {\nsource = \"./s3\"\nbucket_name = var.bucket_name\nfunction_name = module.lambda.function_name\nfunction_arn = module.lambda.function_arn\n}\nmodule \"fotos\" {\nsource = \"./s3_fotos\"\nfotos_name = var.fotos_name\nfunction_name = module.lambda.function_name\nfunction_arn = module.lambda.function_arn\n}\nmodule \"website\" {\nsource = \"./s3_website\"\nwebsite_name = var.website_name\nfunction_name = module.lambda.function_name\nfunction_arn = module.lambda.function_arn\n}\nmodule \"sns\" {\nsource = \"./sns\"\nemail_subscription = var.email\n}\noutput \"sns_arn\" {\nvalue = module.sns.sns_arn\n}\nmodule \"cloudwatch\" {\nsource = \"./cloudwatch\"\nsns_arn = module.sns.sns_arn\n}\nvariable \"bucket_name\" {\ntype = string\ndefault = \"ProjetoBucket130\"\n}\nvariable \"website_name\" {\ntype = string\ndefault = \"ProjetoBucket131\"\n}\nvariable \"fotos_name\" {\ntype = string\ndefault = \"ProjetoBucket132\"\n}\nvariable \"email\" {\ntype = string\ndefault = \"niveaadl@al.insper.edu.br\"\n}\n</code></pre> <p>Caso tudo esteja corretamente, configurado, inicie novamente seu ambiente para carregamento de m\u00f3dulos:</p> <pre><code>terraform init\n</code></pre> <p>Verifique se o acoplamento l\u00f3gico dos recursos \u00e9 coerente (principalmente com as vari\u00e1veis passadas) para resolu\u00e7\u00e3o de problemas:</p> <pre><code>terraform plan\n</code></pre> <p>Caso tudo esteja certo, execute o comando de deploy modificando as vari\u00e1veis para os nomes e email desejados. <pre><code>terraform apply -var=\"email=niveaadl@al.insper.edu\" \\ \n-var=\"fotos_name=bucketfotos3211\"   \\\n-var=\"website_name=bucketwebsite3211\"\\ \n-var=\"bucket_name=bucketname3211\" \\\n-auto-approve\n</code></pre></p> <p>Ao fim da execu\u00e7\u00e3o, voc\u00ea dever\u00e1 ter em seu console a cria\u00e7\u00e3o de:</p> <ul> <li>3 buckets;</li> <li>Fun\u00e7\u00e3o Lambda;</li> <li>T\u00f3pico SNS;</li> <li>Alarme do Cloudwatch;</li> <li>Permiss\u00e3o de execu\u00e7\u00e3o dos recursos;</li> </ul> <p>Finalizando nossa arquitetura desejada na nuvem.</p>"},{"location":"#criando-uma-interface-para-gerenciar-uploads-e-downloads-nos-buckets","title":"Criando uma interface para gerenciar Uploads e Downloads nos Buckets","text":"<p>Apesar de j\u00e1 conseguirmos criar nossa arquitetura funcional em Cloud, \u00e9 um pouco \"massante\" ter que abrir o dashboard para tarefas simples e rotineiras como incluir arquivos e fazer download de outros.</p> <p>Analogamente, seria interessante criar uma estrutura de usu\u00e1rios nessa interface que limita-se as permiss\u00f5es de cada usu\u00e1rio, isto \u00e9, cada user pode apenas ver seus pr\u00f3prios arquivos.</p> <p>Para isso iremos:</p> <ul> <li>Criar uma interface em React para facilitar o gerenciamento de buckets e no\u00e7\u00e3o de usu\u00e1rios;</li> <li>Utilizar SDK da AWS para interagir com os buckets rec\u00e9m criados;</li> </ul> <p>Para isso, inicialmente instale o Node 18&gt;:</p> <pre><code>curl -sL https://deb.nodesource.com/setup_18.x -o nodesource_setup.sh\nsudo bash nodesource_setup.sh\nsudo apt install nodejs\n</code></pre> <p>Volte para o diret\u00f3rio raiz do projeto e crie um app React:</p> <pre><code>npx create-react-app interface\n</code></pre> <p>Configure o npm para utilizarmos recursos de SDK da AWS com React.js:</p> <p><pre><code>npm install aws-sdk\nnpm install  env-cmd\n</code></pre> Ap\u00f3s a instala\u00e7\u00e3o, entre na pasta src do diret\u00f3rio e crie um arquivo .env com as suas credenciais para utiliza\u00e7\u00e3o na SDK da AWS:</p> <pre><code>cd interface/src\nnano .env\n</code></pre> <p>Coloque o seguinte conte\u00fado no arquivo:</p> <pre><code>REACT_APP_AWS_ACCESS_KEY_ID=&lt;access_key_id&gt;\nREACT_APP_AWS_SECRET_ACCESS_KEY=&lt;secret_key&gt;\n</code></pre> <p>No arquivo package.json, adicione a refer\u00eancia ao modulo env-cmd para permitir a utiliza\u00e7\u00e3o das variav\u00e9is de ambiente:</p> package.json<pre><code>...\n\"scripts\": {\n\"start\": \"env-cmd -f ./.env react-scripts start\",\n\"build\": \"react-scripts build\",\n\"test\": \"react-scripts test\",\n\"eject\": \"react-scripts eject\"\n},\n...\n</code></pre> <p>Com isso, coloque no arquivo App.js, o conte\u00fado de nossa aplica\u00e7\u00e3o, onde iremos gerenciar login de usu\u00e1rios e realizar solicita\u00e7\u00f5es diretamente ao Amazon S3:</p> App_js App.js<pre><code>import React, { useEffect,useState } from 'react';\nimport AWS from 'aws-sdk';\nimport './App.css';\n// Configura\u00e7\u00e3o das credenciais da AWS\nAWS.config.update({\naccessKeyId: process.env.REACT_APP_AWS_ACCESS_KEY_ID,\nsecretAccessKey: process.env.REACT_APP_AWS_SECRET_ACCESS_KEY,\n});\nconst s3 = new AWS.S3();\nconst bucketName = '&lt;nome_bucket&gt;'; // Nome do bucket S3\nconst bucketfotosName = '&lt;nome_bucket_fotos&gt;'; // Nome do bucket S3\nconst websiteName = '&lt;nome_bucket_website&gt;'; // Nome do bucket S3\nconst App = () =&gt; {\nconst [selectedFile, setSelectedFile] = useState(null);\nconst [objects, setObjects] = useState([]);\nconst [fotos, setFotos] = useState([]);\nconst [siteObjetcs, setSiteObjetcs] = useState([]);\nconst [showModal, setShowModal] = useState(false);\nconst [user, setUser] = useState('');\nconst [userName, setUserName] = useState('');\n// ============REFRESH itens no bucket a cada novo upload\nconst refreshItems = () =&gt; {\nhandleListObjects();\nhandleListObjectsFotos();\nhandleListObjectsWebsite();\n}\nuseEffect(() =&gt; {\nrefreshItems();\n}, [selectedFile]);\n// ============Gerencia credenciais do usu\u00e1rio no browser\nuseEffect(() =&gt; {\nconst VerifyLoggin = async () =&gt; {\nlet cred = getCredentials();\nconsole.log(cred);\nif (cred.username === null){\nsetShowModal(true);\n}\nelse{\nsetShowModal(false);\nsetUserName(cred.username);\n}\n}\nVerifyLoggin().catch(console.error);\n}, []);\nconst logout = () =&gt; {\nsetUser('');\nsaveCredentials();\nsetShowModal(true)\n};\nconst refresh = () =&gt; window.location.reload(true)\nconst saveCredentials = () =&gt; {\nlet username = user;\nif (user.length === 0){\nusername = null;\n}\nconst credentials = {\nusername\n};\nlocalStorage.setItem('credentials', JSON.stringify(credentials));\n};\nconst getCredentials = () =&gt; {\nconst credentials = localStorage.getItem('credentials');\nif (credentials) {\nreturn JSON.parse(credentials);\n}\nreturn null;\n};\nconst handleModal = () =&gt; {\nsetShowModal(!showModal);\n};\n// =================UPLOAD nos BUCKETS==================\nconst handleFileUpload = async () =&gt; {\nif (!selectedFile) {\nconsole.log('Nenhum arquivo selecionado.');\nreturn;\n}\nconst fileName = selectedFile.name;\nconst uploadParams = {\nBucket: bucketName,\nKey: userName+\"/\" + fileName,\nBody: selectedFile,\n};\ntry {\nawait s3.upload(uploadParams).promise();\nconsole.log('Arquivo enviado com sucesso.');\n} catch (error) {\nconsole.error('Erro ao enviar arquivo:', error);\n}\n};\nconst handleFileUploadFotos = async () =&gt; {\nif (!selectedFile) {\nconsole.log('Nenhum arquivo selecionado.');\nreturn;\n}\nconst fileName = selectedFile.name;\nconst uploadParams = {\nBucket: bucketfotosName,\nKey: userName+\"/\" + fileName,\nBody: selectedFile,\n};\ntry {\nawait s3.upload(uploadParams).promise();\nconsole.log('Arquivo enviado com sucesso.');\n} catch (error) {\nconsole.error('Erro ao enviar arquivo:', error);\n}\n};\nconst handleFileUploadWebsite = async () =&gt; {\nif (!selectedFile) {\nconsole.log('Nenhum arquivo selecionado.');\nreturn;\n}\nconst fileName = selectedFile.name;\nconst uploadParams = {\nBucket: websiteName,\nKey: userName+\"/\" + fileName,\nBody: selectedFile,\n};\ntry {\nawait s3.upload(uploadParams).promise();\nconsole.log('Arquivo enviado com sucesso.');\n} catch (error) {\nconsole.error('Erro ao enviar arquivo:', error);\n}\n};\n// =================DOWNLOAD dos BUCKETS==================\nconst handleFileDownload = async (fileName) =&gt; {\nconst downloadParams = {\nBucket: bucketName,\nKey: fileName,\n};\ntry {\nconst data = await s3.getObject(downloadParams).promise();\nconsole.log('Dados do arquivo:', data);\nconst fileBlob = new Blob([data.Body]);\nconst fileUrl = URL.createObjectURL(fileBlob);\nconst link = document.createElement('a');\nlink.href = fileUrl;\nlink.download = fileName;\nlink.click();\nURL.revokeObjectURL(fileUrl);\n} catch (error) {\nconsole.error('Erro ao baixar o arquivo:', error);\n}\n};\nconst handleFileDownloadFotos = async (fileName) =&gt; {\nconst downloadParams = {\nBucket: bucketfotosName,\nKey: fileName,\n};\ntry {\nconst data = await s3.getObject(downloadParams).promise();\nconsole.log('Dados do arquivo:', data);\nconst fileBlob = new Blob([data.Body]);\nconst fileUrl = URL.createObjectURL(fileBlob);\nconst link = document.createElement('a');\nlink.href = fileUrl;\nlink.download = fileName;\nlink.click();\nURL.revokeObjectURL(fileUrl);\n} catch (error) {\nconsole.error('Erro ao baixar o arquivo:', error);\n}\n};\nconst handleFileDownloadWebsite = async (fileName) =&gt; {\nconst downloadParams = {\nBucket: websiteName,\nKey: fileName,\n};\ntry {\nconst data = await s3.getObject(downloadParams).promise();\nconsole.log('Dados do arquivo:', data);\nconst fileBlob = new Blob([data.Body]);\nconst fileUrl = URL.createObjectURL(fileBlob);\nconst link = document.createElement('a');\nlink.href = fileUrl;\nlink.download = fileName;\nlink.click();\nURL.revokeObjectURL(fileUrl);\n} catch (error) {\nconsole.error('Erro ao baixar o arquivo:', error);\n}\n};\n// =================Listagem de objetos dos BUCKETS para o usu\u00e1rio==================\nconst handleListObjects = async () =&gt; {\nconst listParams = {\nBucket: bucketName,\nPrefix: userName+\"/\",\n};\ntry {\nconst data = await s3.listObjectsV2(listParams).promise();\nsetObjects(data.Contents);\nconsole.log('Objetos no bucket:', data.Contents);\n} catch (error) {\nconsole.error('Erro ao listar objetos:', error);\n}\n};\nconst handleListObjectsFotos = async () =&gt; {\nconst listParams = {\nBucket: bucketfotosName,\nPrefix: userName+\"/\",\n};\ntry {\nconst data = await s3.listObjectsV2(listParams).promise();\nsetFotos(data.Contents);\nconsole.log('Objetos no bucket:', data.Contents);\n} catch (error) {\nconsole.error('Erro ao listar objetos:', error);\n}\n};\nconst handleListObjectsWebsite = async () =&gt; {\nconst listParams = {\nBucket: websiteName,\nPrefix: userName+\"/\",\n};\ntry {\nconst data = await s3.listObjectsV2(listParams).promise();\nsetSiteObjetcs(data.Contents);\nconsole.log('Objetos no bucket:', data.Contents);\n} catch (error) {\nconsole.error('Erro ao listar objetos:', error);\n}\n};\n// ============Gerenciamento de arquivo\nconst handleSubmit = (event) =&gt; {\nevent.preventDefault();\n};\nconst handleFileChange = (event) =&gt; {\nsetSelectedFile(event.target.files[0]);\n};\nreturn (\n&lt;div className='App'&gt;\n&lt;header className='App-header'&gt;\n&lt;div className='bar'&gt;\n&lt;h1 &gt;S3 Management Tool&lt;/h1&gt;\n&lt;div className='log'&gt;\n&lt;h3&gt;User: {userName}&lt;/h3&gt;\n&lt;button className='logout' onClick={logout}&gt;Logout&lt;/button&gt;\n&lt;/div&gt;\n&lt;/div&gt;\n{showModal &amp;&amp; (\n&lt;div className=\"modal\"&gt;\n&lt;div className=\"modal-content\"&gt;\n&lt;h2&gt;Login&lt;/h2&gt;\n&lt;p&gt;Username&lt;/p&gt;\n&lt;input\nclassName=\"login-input\"\nplaceholder=\"Username\"\nvalue={user}\nonChange={(e) =&gt; setUser(e.target.value)}\nrequired\n/&gt;\n&lt;div className=\"modal-buttons\"&gt;\n&lt;button className=\"buttons\" onClick={() =&gt; {saveCredentials();setShowModal(false);refresh()}}&gt;Login&lt;/button&gt;\n&lt;/div&gt;\n&lt;/div&gt;\n&lt;/div&gt;\n)}\n&lt;div className='blocks'&gt;\n&lt;div className='block'&gt;\n&lt;h1 className='font'&gt;Novo upload&lt;/h1&gt;\n&lt;div className='buttons'&gt;\n&lt;input type=\"file\" onChange={handleFileChange} /&gt;\n&lt;button onClick={handleFileUpload}&gt;Upload em {bucketName}&lt;/button&gt;\n&lt;button onClick={handleFileUploadFotos}&gt;Upload em {bucketfotosName}&lt;/button&gt;\n&lt;button onClick={handleFileUploadWebsite}&gt;Upload em {websiteName}&lt;/button&gt;\n&lt;/div&gt;\n&lt;/div&gt;\n&lt;div className='block'&gt;\n&lt;h1 className='font'&gt;Objetos em {bucketName}&lt;/h1&gt;\n&lt;div className='buttons'&gt;\n{objects.map((item, index) =&gt; (\n&lt;div key={index} &gt;\n&lt;button key={index} onClick={()=&gt;handleFileDownload(item.Key)} &gt;{item.Key.split('/')[1]}&lt;/button&gt;\n&lt;/div&gt;))\n}\n&lt;/div&gt;\n&lt;/div&gt;\n&lt;/div&gt;\n&lt;div className='blocks'&gt;\n&lt;div className='block'&gt;\n&lt;h1 className='font'&gt;Objetos em {bucketfotosName}&lt;/h1&gt;\n&lt;div className='buttons'&gt;\n{fotos.map((item, index) =&gt; (\n&lt;div key={index} &gt;\n&lt;button key={index} onClick={()=&gt;handleFileDownloadFotos(item.Key)} &gt;{item.Key.split('/')[1]}&lt;/button&gt;\n&lt;/div&gt;))\n}\n&lt;/div&gt;\n&lt;/div&gt;\n&lt;div className='block'&gt;\n&lt;h1 className='font'&gt;Objetos em {websiteName}&lt;/h1&gt;\n&lt;div className='buttons'&gt;\n{siteObjetcs.map((item, index) =&gt; (\n&lt;div key={index} &gt;\n&lt;button key={index} onClick={()=&gt;handleFileDownloadWebsite(item.Key)} &gt;{item.Key.split('/')[1]}&lt;/button&gt;\n&lt;/div&gt;))\n}\n&lt;/div&gt;\n&lt;/div&gt;\n&lt;/div&gt;\n&lt;/header&gt;\n&lt;/div&gt;\n);\n};\nexport default App;\n</code></pre> <p>Coloque tamb\u00e9m a estiliza\u00e7\u00e3o do site:</p> App_css App.css<pre><code>      .App {\ntext-align: center;\n}\n.App-logo {\nheight: 40vmin;\npointer-events: none;\n}\n.bar{\ndisplay: flex;\nflex-direction: row;\nalign-items: center;\njustify-content: center;\nwidth: 100%;\nbackground-color: white;\ntop: 0;\nz-index: 100;\nbackground-color: rgb(2, 65, 124);\n}\n.log{\nposition: absolute;\nright:0;\ndisplay: flex;\nflex-direction: column;\njustify-content: center;\nalign-items: center;\n}\n.blocks {\ndisplay: flex;\nflex-direction: row;\n}\n.block{\nbackground-image: linear-gradient(rgb(244, 138, 138), rgb(193, 4, 11));\nmargin: 30px;\nborder-radius: 40px;\npadding: 30px;\nmin-width: 30rem;\nmin-height: 10rem;\n}\n@media (prefers-reduced-motion: no-preference) {\n.App-logo {\nanimation: App-logo-spin infinite 20s linear;\n}\n}\n.App-header {\nposition: relative;\ndisplay:flex;\nbackground-image: linear-gradient(rgb(255, 0, 0), rgb(244, 83, 89));\nmin-height: 100vh;\nflex-direction: column;\nalign-items: center;\n/* justify-content: space-between; */\nfont-size: calc(10px + 2vmin);\ncolor: white;\nheight: auto;\nmargin: 0 auto;\n}\n.App-link {\ncolor: #61dafb;\n}\n@keyframes App-logo-spin {\nfrom {\ntransform: rotate(0deg);\n}\nto {\ntransform: rotate(360deg);\n}\n}\n.modal {\nposition: fixed;\nz-index: 100;\ntop: 0;\nleft: 0;\nwidth: 100%;\nheight: 100%;\nbackground-color: rgba(0, 0, 0, 0.5);\ndisplay: flex;\njustify-content: center;\nalign-items: center;\n}\n.modal-content {\ndisplay: flex;\nflex-direction: column;\njustify-content: center;\nbackground-image: linear-gradient(rgb(255, 130, 77), rgb(250, 2, 2));\npadding: 20px;\nborder-radius: 40px;\n}\n.modal-content h2 {\nmargin-top: 0;\n}\n.modal-buttons {\ndisplay: flex;\njustify-content: center;\nmargin-top: 20px;\ntext-decoration: none; }\n.modal-buttons button {\nmargin:10px;\ncolor: rgb(0, 0, 0);\nborder: none;\nbackground-image: linear-gradient(rgb(252, 102, 102), rgb(249, 60, 22));\nborder-radius: 5px;\nfont-size: 2rem;\noutline: none; text-decoration:none;\ntransition-duration: 0.4s;\n}\n.modal-buttons button:hover{\ntransform: scale(1.03);\ncolor:rgb(7, 88, 227);\n}\n.buttons{\ndisplay: flex;\nflex-direction: column;\n}\n.font{\nfont-size: 2rem;\n}\n</code></pre> <p>Com arquivos locais configurados, execute na pasta interface/:</p> <pre><code>npm start\n</code></pre> <p>Ap\u00f3s carregamento, na porta 3000, voc\u00ea dever\u00e1 ver a interface, onde voc\u00ea pode colocar o seu nome de usu\u00e1rio que poder\u00e1 interagir e ter suas permiss\u00f5es no Bucket:</p> <p>Ap\u00f3s logar como \"nivea\", voc\u00ea ver\u00e1 que a interface lista os objetos em cada um dos tr\u00eas buckets pertecentes ao usu\u00e1rio logado (por enquanto nenhum) e d\u00e1 a op\u00e7\u00e3o de upload de arquivos em cada um dos buckets:</p> <p>Ao se realizar o upload de um arquivo para o bucket padr\u00e3o e o bucket de fotos, podemos ver que eles j\u00e1 aparecem dispon\u00edveis na interface:</p> <p>Ao clicar nos arquivos dentro dos buckets, \u00e9 realizado o download destes:</p> <p>Caso deslogarmos, e entrarmos em um novo usu\u00e1rio chamado \"rodolfo\", podemos ver que os arquivos pertencentes ao usu\u00e1rio \"nivea\" n\u00e3o s\u00e3o mostrados a ele (gerenciado permiss\u00f5es via interface):</p> <p>Analogamente, quando este realiza upload de seus arquivos, apenas seus arquivos s\u00e3o mostrados nos buckets:</p> <p>Na dashboard da AWS, podemos ver que h\u00e1 uma n\u00edtida divis\u00e3o entre as pastas para cada usu\u00e1rio, e, a cada novo usu\u00e1rio cadastrado, uma nova pasta (Prefix) ser\u00e1 criada, gerando assim uma no\u00e7\u00e3o de permiss\u00f5es diferentes para cada usu\u00e1rio \u00e0 nivel de aplica\u00e7\u00e3o:</p> <p>Por fim, podes averiguar que o email cadastrado no t\u00f3pico tamb\u00e9m \u00e9 notificado quando um novo objeto \u00e9 inserido:</p> <p>E dessa forma, encerramos nossa arquitetura e projeto. Conforme podem ver pelas figuras acima, a aplica\u00e7\u00e3o \u00e9 de cunho de prova de conceito e deve ser utilizada apenas com  intuito de entendimento de recursos em Cloud e n\u00e3o em ambientes de produ\u00e7\u00e3o.</p> <p>Agrade\u00e7o a todos que leram este roteiro at\u00e9 o final, em especial os professores da disciplina, Rodolfo Avelino e Tiago Demay.</p>"}]}