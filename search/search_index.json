{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Ferramenta de Gerenciamento do Amazon S3","text":"<p>Esta \u00e9 uma ferramenta/produto de gerenciamento de buckets S3, instancias de armazenamento, com templates terraform tipo como se fosse um \"google drive\". </p> <p>Com esta ferramenta, ser\u00e1  poss\u00edvel criar-se novos buckets no S3, gerenciar suas permiss\u00f5es de acesso, cria\u00e7\u00e3o de folders, cria\u00e7\u00e3o de pol\u00edticas. Ser\u00e1 poss\u00edvel tamb\u00e9m a listagem de buckets na conta do usu\u00e1rios, objetos em um bucket especificado, configura\u00e7\u00f5es de lifecycle. </p> <p>Por fim, pretende-se a cria\u00e7\u00e3o de uma simples interface web que possibilite o upload de objetos no bucket, assim como listagem,  download e exclus\u00e3o destes caso seja do desejo do usu\u00e1rio. Notifica\u00e7\u00e3o para saber qual bucket foi modificado.</p>"},{"location":"#pre-requisitos","title":"Pr\u00e9 requisitos","text":"<p>Para execu\u00e7\u00e3o adequada deste roteiro, s\u00e3o necess\u00e1rios os seguintes pr\u00e9-requisitos:</p> <ul> <li>Ubuntu &gt; 20.0 ou WSL2</li> <li>Terraform</li> <li>Python &gt; 3.6</li> <li>Conta na AWS com usu\u00e1rio com permiss\u00f5es de administrador</li> </ul>"},{"location":"#recursos-essenciais-da-ferramenta","title":"Recursos essenciais da ferramenta","text":"<p>Queremos, ao fim desse roteiro, provisionar uma arquitetura como a abaixo:</p> <p>Que ser\u00e1 capaz de criar um sistema de armazenamento de arquivos e at\u00e9 site est\u00e1tico, com funcionalidade de gerar notifica\u00e7\u00f5es ao dono desses recursos para cada objeto adicionado nos buckets, criando assim al\u00e9m de grande disponibilidade e facilidade de uso, uma arquitetura altamente rastre\u00e1vel, permitindo a verifica\u00e7\u00e3o mais r\u00e1pido de erros e brechas de seguran\u00e7a.</p>"},{"location":"#aws","title":"AWS","text":"<p>\u00c9 uma plataforma de servi\u00e7os de computa\u00e7\u00e3o em nuvem oferecida pela Amazon, que permite que indiv\u00edduos e organiza\u00e7\u00f5es implementem aplicativos, servi\u00e7os e infraestrutura na nuvem. A AWS oferece uma ampla variedade de servi\u00e7os em nuvem, incluindo computa\u00e7\u00e3o, armazentamento, banco de dados, an\u00e1lise, intelig\u00eancia artificial, machine learning e muito mais.</p> <p>Para conseguir interagir com os servi\u00e7os e fun\u00e7\u00f5es que a AWS prov\u00e9m, por meio de IaC (Infrastructure as Code), \u00e9 necess\u00e1rio obter chaves de acesso, que permitam o gerenciamento e provisionamento dos recursos que desejamos alocar na nuvem.</p> <p>De posse de suas respectivas chaves de acesso, crie duas vari\u00e1veis de ambiente, conforme padr\u00e3o abaixo:</p> <p><pre><code>export AWS_ACCESS_KEY_ID=&lt;ID_CHAVE_DE_ACESSO&gt;\nexport AWS_SECRET_ACCESS_KEY=&lt;CHAVE_SECRETA_DE_ACESSO&gt;\n</code></pre> Realiza-se o acesso a essas chaves para seguran\u00e7a de dados de quem acessa, pois assim evita-se sempre ter que colocar a senha no ambiente e a senha estar exposta</p>"},{"location":"#s3","title":"S3","text":"<p>\u00c9 um servi\u00e7o de armanezamento de objetos oferecido pela Amazon Web Services (AWS). O S3 permite que os usu\u00e1rios armazenem e recuperem arquivos de qualquer lugar da web. O S3 \u00e9 amplamente utilizado por empresas e organiza\u00e7\u00f5es de diferentes setores para armazenamento e compartilhamento de arquivos, backup e arquivamento de dados, hospedagem de sites e aplicativos, e muito mais.</p>"},{"location":"#bucket","title":"Bucket","text":"<p>Bucket \u00e9 um conceito de armazenamento usado em servi\u00e7os de armazenamento em nuvem, como o Amazon S3. Um bucket pode ser considerado como um cont\u00eainer de objetos, que pode armazenar e gerenciar v\u00e1rios objetos, como arquivos, imagens, v\u00eddeos, entre outros. Os buckets s\u00e3o amplamente utilizados para hospedar sites est\u00e1ticos, armazenamento de backup, arquivamento de dados e muito mais. Eles s\u00e3o uma parte essencial de muitos servi\u00e7os em nuvem e permitem que os usu\u00e1rios armazenem, gerenciem e acessem dados de qualquer lugar da web.</p>"},{"location":"#terraform","title":"Terraform","text":"<p>\u00c9 uma infraestrutura que descreve os recursos que voc\u00ea deseja provisionar, como servidores, banco de dados e outros. Al\u00e9m disso, voc\u00ea pode usar o Terraform para criar, alterar e destruir recursos automaticamente.</p>"},{"location":"#s3-events","title":"S3 Events","text":"<p>O Amazon S3 Events permite que voc\u00ea monitore altera\u00e7\u00f5es em seu bucket do Amazon S3 e responda essas altera\u00e7\u00f5es executando a\u00e7\u00f5es autom\u00e1ticas. Quando um evento ocorre em seu bucket como upload de um arquivo ou a exclus\u00e3o de um objeto o S3 Events pode acusar uma a\u00e7\u00e3o autom\u00e1tica como a invoca\u00e7\u00e3o de uma fun\u00e7\u00e3o AWS Lambda ou a notifica\u00e7\u00e3o de um t\u00f3pico do Amazon Simple Notificacion Service (SNS).</p>"},{"location":"#funcao-aws-lambda","title":"Fun\u00e7\u00e3o AWS Lambda","text":"<p>As Fun\u00e7\u00f5es AWS Lambda fazem o processamento de eventos em tempo real como logs e notifica\u00e7\u00f5es. Por exemplo, voc\u00ea pode criar uma fun\u00e7\u00e3o lambda que \u00e9 acionada sempre que um novo objeto \u00e9 enviado para um bucket do Amazon S3. A fun\u00e7\u00e3o pode processar o objeto, extrair informa\u00e7\u00f5es relevantes, executar transforma\u00e7\u00f5es ou armazenar dados em outros servi\u00e7o. </p>"},{"location":"#amazon-simple-notification-service-sns","title":"Amazon Simple Notification Service (SNS)","text":"<p>O SNS \u00e9 um servi\u00e7o de mensagens e notifica\u00e7\u00e3o da AWS que permite enviar mensagens para diferentes tipos de endpoints como emails, mensagens de texto(SMS), URLs entre outros. Al\u00e9m disso, voc\u00ea pode configurar o acesso para quem pode publicar e para quem pode se inscrever no t\u00f3pico.</p>"},{"location":"#cloudwatch-alarm","title":"CloudWatch Alarm","text":"<p>O CloudWatch Alarm \u00e9 um servi\u00e7o de monitoramento e observabilidade da AWS. O CloudWatch Alarm permite monitorar m\u00e9tricas espec\u00edficas e acionar a\u00e7\u00f5es autom\u00e1ticas com base em condi\u00e7\u00f5es predefinidas.</p>"},{"location":"#iniciando-nossa-infraestrutura","title":"Iniciando nossa infraestrutura","text":"<p>Crie uma pasta para organizar nossos arquivos chamada terraform/::</p> <pre><code>mkdir terraform cd terraform\n</code></pre> <p>Como nosso primeiro objetivo \u00e9 criar um bucket na AWS crie um template chamado s3.tf com o seguinte conte\u00fado:</p> s3.tf<pre><code>#Provider and default region used\nprovider \"aws\" {\nregion     = \"us-east-2\"\n}\nresource \"aws_s3_bucket\" \"exemplo\" {\nbucket = \"&lt;Nome do bucket&gt;\"\ntags = {\nName        = \"My bucket\"\nEnvironment = \"Dev\"\n}\n}\n</code></pre> <p> Subistitua o nome do bucket pelo que voc\u00ea deseja, lembrando que esse nome \u00e9 \u00fanico em toda AWS</p> <p>Inicie ent\u00e3o os recursos terraform necess\u00e1rios para provisionar rodando o comando abaixo:</p> <pre><code>terraform init\n</code></pre> <p>Agora veremos o plano de cria\u00e7\u00e3o desses recursos:</p> <pre><code>terraform plan\n</code></pre> <p>Por fim, realize deploy deste recurso na nuvem:</p> <pre><code>terraform apply -auto-approve\n</code></pre> <p>Caso tudo d\u00ea certo voc\u00ea ver\u00e1 isso no console da AWS</p>"},{"location":"#como-subir-um-site-estatico-por-terraform","title":"Como subir um site est\u00e1tico por Terraform","text":"<p>Agora que j\u00e1 conseguimos subir um bucket privado de uso geral, podemos tamb\u00e9m modificar nossa infraestrutura para provisionar buckets que disponibilizem p\u00e1ginas est\u00e1ticas, conforme nosso plano de infraestrutura. Para isso, devemos...</p> <ul> <li>Fazer um provedor de nuvem da AWS</li> <li>Especificar o recurso que se quer criar : um bucket</li> <li>Define-se os controles do bucket</li> <li>Definir os acesso publico pra tirar esse bloqueio do </li> <li>Definir qual o acesso do bucket</li> <li>Definir uma nova configura\u00e7\u00e3o de bucket</li> <li>Pol\u00edtica de acesso a leitura do bucket</li> <li>Configura\u00e7\u00f5es e buckets de indexar pagina </li> </ul> <p>Para isso, crie um novo arquivo chamado s3_website, que ir\u00e1 realizar os passos acima:</p> s3_website.tf<pre><code>provider \"aws\" {\nregion = \"us-east-1\" # Substitua pela regi\u00e3o desejada\n}\nresource \"aws_s3_bucket\" \"website\" {\nbucket = \"bucketdanivinhaprojeto21\"\n}\nresource \"aws_s3_bucket_ownership_controls\" \"example\" {\nbucket = aws_s3_bucket.website.id\nrule {\nobject_ownership = \"BucketOwnerPreferred\"\n}\n}\nresource \"aws_s3_bucket_public_access_block\" \"example\" {\nbucket = aws_s3_bucket.website.id\nblock_public_acls       = false\nblock_public_policy     = false\nignore_public_acls      = false\nrestrict_public_buckets = false\n}\nresource \"aws_s3_bucket_acl\" \"example\" {\ndepends_on = [\naws_s3_bucket_ownership_controls.example,\naws_s3_bucket_public_access_block.example,\n]\nbucket = aws_s3_bucket.website.id\nacl    = \"public-read\"\n}\nresource \"aws_s3_bucket_versioning\" \"website\" {\nbucket = aws_s3_bucket.website.id\nversioning_configuration {\nstatus = \"Enabled\"\n}\n}\ndata \"aws_caller_identity\" \"current\" {}\nresource \"aws_s3_bucket_policy\" \"public_read_access\" {\nbucket = aws_s3_bucket.website.id\npolicy = data.aws_iam_policy_document.public_read_access.json\n}\ndata \"aws_iam_policy_document\" \"public_read_access\" {\nstatement {\nprincipals {\ntype = \"*\"\nidentifiers = [\"*\"]\n}\nactions = [\n\"s3:GetObject\",\n\"s3:ListBucket\",\n]\nresources = [\naws_s3_bucket.website.arn,\n\"${aws_s3_bucket.website.arn}/*\",\n]\n}\n}\nresource \"aws_s3_bucket_website_configuration\" \"website\" {\nbucket = aws_s3_bucket.website.bucket\nindex_document {\nsuffix = \"index.html\"\n}\n}\nresource \"aws_s3_object\" \"index_page\" {\nbucket       = aws_s3_bucket.website.id\nkey          = \"index.html\"\ncontent_type = \"text/html; charset=UTF-8\"\nsource       = \"index.html\"\n} </code></pre> <p>Na mesma pasta crie um arquivo chamado index.html e coloque o seguinte conte\u00fado nele:</p> <pre><code>&lt;h1&gt;Hello World&lt;/h1&gt;\n</code></pre> <p>Inicie ent\u00e3o os recursos terraform necess\u00e1rios para provisionar rodando o comando abaixo:</p> <pre><code>terraform init\n</code></pre> <p>Agora veremos o plano de cria\u00e7\u00e3o desses recursos:</p> <pre><code>terraform plan\n</code></pre> <p>Por fim, realize deploy deste recurso na nuvem:</p> <pre><code>terraform apply -auto-approve\n</code></pre> <p>Caso tudo d\u00ea certo voc\u00ea ver\u00e1 isso no console da AWS</p> <p>E a pagina voc\u00ea ver\u00e1 isso</p> <p>Fica disponibilizado o link em que voc\u00ea pode verificar:</p> <pre><code>http://bucketdanivinhaprojeto21.s3-website-us-east-1.amazonaws.com\n</code></pre>"},{"location":"#s3-events-engatilhando-uma-funcao-lambda","title":"S3 events engatilhando uma fun\u00e7\u00e3o Lambda","text":"<p>J\u00e1 conseguimos criar diferentes buckets que contemplam sua fun\u00e7\u00e3o: </p> <p>Armazenar objetos</p> <p>Para se adequar a nossa arquitetura desejada, devemos ent\u00e3o integrar o S3 events, um notificador de eventos pr\u00f3prio do Amazon S3 para engatilhar uma fun\u00e7\u00e3o Lambda a cada vez que um novo objeto for adicionado neste bucket.</p> <p>Para isso, precisamos ent\u00e3o:</p> <ul> <li>Configurar S3 events nos buckets que j\u00e1 possu\u00edmos;</li> <li>Criar um template que provisiona uma fun\u00e7\u00e3o Lambda que ser\u00e1 engatilhada por esse evento</li> <li>Criar permiss\u00f5es que autorizem o S3 events a engatilhar a fun\u00e7\u00e3o.</li> </ul> <p>Para isso, iremos utilizar m\u00f3dulos do terraform, para melhorar a organiza\u00e7\u00e3o de nossos templates e tamb\u00e9m facilitar a conex\u00e3o entre esses templates, conforme ser\u00e1 necess\u00e1rio.</p> <p>Crie tr\u00eas pastas, chamadas respectivamente lambda, s3 e s3_website:</p> <pre><code>mkdir lambda\nmkdir s3\nmkdir s3_website\n</code></pre> <p>Mova o arquivo s3.tf para a pasta s3/, s3_website.tf para s3_website/ e crie um arquivo lambda.tf para a pasta lambda/. N\u00e3o coloque nada nesse arquivo ainda.</p> <p>Modifique o arquivo s3.tf, adicionando os componentes de permiss\u00e3o para a execu\u00e7\u00e3o da Lambda e notifica\u00e7\u00e3o do S3.</p> s3.tf<pre><code>variable \"function_name\" {\ntype = string\n}\nvariable \"function_arn\" {\ntype = string\n}\nresource \"aws_s3_bucket\" \"exemplo\" {\nbucket = \"bucket-nivea-456864\"\ntags = {\nName        = \"My bucket\"\nEnvironment = \"Dev\"\n}\n}\nresource \"aws_lambda_permission\" \"exemplo\" {\nstatement_id  = \"example-statement-id\"\naction        = \"lambda:InvokeFunction\"\nfunction_name =  var.function_name\nprincipal     = \"s3.amazonaws.com\"\nsource_arn    = \"${aws_s3_bucket.exemplo.arn}/\"\n}\nmodule \"s3_notification\" {\nsource  = \"terraform-aws-modules/s3-bucket/aws//modules/notification\"\nversion = \"~&gt; 3.0\"\nbucket = aws_s3_bucket.exemplo.id\neventbridge = true\nlambda_notifications = {\nlambda = {\nfunction_arn  = var.function_arn\nfunction_name = var.function_name\nevents        = [\"s3:ObjectCreated:*\"]\n}\n}\n}\n</code></pre> <p>Dentro da pasta lambda/, crie um arquivo chamado events.py, com o seguinte conte\u00fado:</p> events.py<pre><code>import json \ndef lambda_handler(event, context):\nprint(\"Novo objeto adicionado\")\nreturn {\n'statusCode': 200,\n'body': json.dumps('Hello from Lambda!')\n}\n</code></pre> <p>Compacte  fun\u00e7\u00e3o usando seu compactador preferido (Winrar, Zip e etc), para criar um arquivo chamado events.zip que contenha o arquivo events.py.</p> <p>Crie ent\u00e3o o arquivo lambda.tf na atual pasta, que ir\u00e1 criar:</p> <ul> <li>A fun\u00e7\u00e3o propriamente dita, com sua linguagem de programa\u00e7\u00e3o, nome e outras configura\u00e7\u00f5es;</li> <li>Role com permiss\u00f5es necess\u00e1rias;</li> <li>Pol\u00edticas de permiss\u00f5es necess\u00e1rias;</li> <li>Output para passar detalhes da fun\u00e7\u00e3o para o template do S3.</li> </ul> <p>Assim crie:</p> lambda.tf<pre><code>resource \"aws_lambda_function\" \"example\" {\nfunction_name = \"events\"\nruntime = \"python3.8\"\nhandler = \"events.lambda_handler\"\nrole = aws_iam_role.lambda.arn\nfilename = \"lambda/events.zip\"\nenvironment {\nvariables = {\nEXAMPLE_VARIABLE = \"example_value\"\n}\n}\n}\nresource \"aws_iam_role\" \"lambda\" {\nname = \"a1s3-events-execution-lambda\"\nassume_role_policy = jsonencode({\nVersion = \"2012-10-17\"\nStatement = [\n{\nAction = \"sts:AssumeRole\"\nEffect = \"Allow\"\nPrincipal = {\nService = \"lambda.amazonaws.com\"\n}\n}\n]\n})\n}\nresource \"aws_iam_role_policy_attachment\" \"lambda\" {\npolicy_arn = \"arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole\"\nrole       = aws_iam_role.lambda.name\n}\noutput \"function_name\" {\nvalue = aws_lambda_function.example.function_name\n}\noutput \"function_arn\" {\nvalue = aws_lambda_function.example.arn\n}\n</code></pre> <p>Retorne para o diret\u00f3rio terraform/: <pre><code>cd ..\n</code></pre></p> <p>Crie um arquivo main.tf, que ir\u00e1 reunir e referenciar os m\u00f3dulos agora criados:</p> <ul> <li>M\u00f3dulo Lambda e seus outputs(nome e ARN);</li> <li>M\u00f3dulo S3;</li> <li>M\u00f3dulo S3-Website</li> </ul> main.tf<pre><code>provider \"aws\" {\nregion     = \"us-east-1\"\n}\nmodule \"lambda\" {\nsource = \"./lambda\"\n}\noutput \"function_name\" {\nvalue = module.lambda.function_name\n}\noutput \"function_arn\" {\nvalue = module.lambda.function_arn\n}\nmodule \"s3\" {\nsource = \"./s3\"\nfunction_name = module.lambda.function_name\nfunction_arn = module.lambda.function_arn\n}\nmodule \"website\" {\nsource = \"./s3_website\"\n}\n</code></pre> <p>Dessa forma sua organiza\u00e7\u00e3o de diret\u00f3rio deve ficar assim:</p> <pre><code>terraform/\n  |\n  ------main.tf\n  |\n  ------lambda/\n      |\n      ------lambda.tf\n  |\n  ------s3/\n      |\n      ------s3.tf\n  |\n  ------s3_website/\n      |\n      ------s3_website.tf\n</code></pre> <p>Rode em seu terminal para iniciar novamente o backend:</p> <pre><code>terraform init\n</code></pre> <p>Veja se o acoplamento l\u00f3gico dos componentes est\u00e1 correto:</p> <pre><code>terraform plan\n</code></pre> <p>Aplique as mudan\u00e7as:</p> <p><pre><code>terraform apply -auto-approve\n</code></pre> Estando tudo correto, voc\u00ea dever\u00e1 em seu console, al\u00e9m dos buckets anteriormente criados, a seguinte fun\u00e7\u00e3o:</p>"},{"location":"#criando-um-topico-de-notificacoes-no-sns","title":"Criando um t\u00f3pico de notifica\u00e7\u00f5es no SNS","text":"<p>At\u00e9 ent\u00e3o conseguimos provisionar um bucket e uma fun\u00e7\u00e3o Lambda engatilhada a cada novo objeto adicionado neste bucket.  Precisamos ent\u00e3o, criar uma notifica\u00e7\u00e3o que avise algum dos desenvolvedores ou dono da infraestrutura, que um novo objeto foi adicionado, gerando assim, maior controle da infraestrutura e suas mudan\u00e7as.</p> <p>Dessa forma, iremos utilizar o SNS, que conforme explicado no come\u00e7o deste roteiro, tem por seu fim, enviar notifica\u00e7\u00f5es para diferentes meios, como email, SMS, HTTP e outros. Para este projeto, iremos configurar um t\u00f3pico SNS que ir\u00e1 enviar uma solicita\u00e7\u00e3o par um email cadastrado.</p> <p>Dessa forma, crie uma pasta chamada SNS/ dentro do diret\u00f3rio terraform/, e adicione o arquivo sns.tf.</p> <p>Este ir\u00e1 conter:</p> <ul> <li>O nome do t\u00f3pico a ser criado;</li> <li>O protocolo de envio do t\u00f3pico (email) e a endpoit de envio (seu endere\u00e7o de email);</li> <li>E um output do ARN do recurso criado para uso posterior.</li> </ul> <p>Assim, coloque no arquivo sns.tf:</p> sns.tf<pre><code>resource \"aws_sns_topic\" \"example_topic\" {\nname = \"example-topic\"\n}\nvariable \"email_subscription\" {\ntype    = string\ndefault = \"teste@al.insper.edu.br\" # Insira seu email\n}\nresource \"aws_sns_topic_subscription\" \"email_subscription\" {\ntopic_arn = aws_sns_topic.example_topic.arn\nprotocol  = \"email\"\nendpoint  = var.email_subscription\n}\noutput \"sns_arn\" {\nvalue = aws_sns_topic.example_topic.arn\n}\n</code></pre> <p>Dessa forma sua organiza\u00e7\u00e3o de diret\u00f3rio deve ficar assim:</p> <pre><code>terraform/\n  |\n  ------main.tf\n  |\n  ------lambda/\n      |\n      ------lambda.tf\n  |\n  ------sns/\n      |\n      ------sns.tf\n  |\n  ------s3/\n      |\n      ------s3.tf\n  |\n  ------s3_website/\n      |\n      ------s3_website.tf\n</code></pre> <p>Retorne para o diret\u00f3rio terraform/ e adeque seu arquivo main.tf para conter o m\u00f3dulo sns/:</p> main.tf<pre><code>provider \"aws\" {\nregion     = \"us-east-1\"\n}\nmodule \"lambda\" {\nsource = \"./lambda\"\n}\noutput \"function_name\" {\nvalue = module.lambda.function_name\n}\noutput \"function_arn\" {\nvalue = module.lambda.function_arn\n}\nmodule \"s3\" {\nsource = \"./s3\"\nfunction_name = module.lambda.function_name\nfunction_arn = module.lambda.function_arn\n}\nmodule \"website\" {\nsource = \"./s3_website\"\n}\nmodule \"sns\" {\nsource = \"./sns\"\n}\noutput \"sns_arn\" {\nvalue = module.sns.sns_arn\n}\n</code></pre> <p>Rode em seu terminal para iniciar novamente o backend:</p> <pre><code>terraform init\n</code></pre> <p>Veja se o acoplamento l\u00f3gico dos componentes est\u00e1 correto:</p> <pre><code>terraform plan\n</code></pre> <p>Aplique as mudan\u00e7as:</p> <p><pre><code>terraform apply -auto-approve\n</code></pre> Estando tudo correto, voc\u00ea dever\u00e1 em seu console, o t\u00f3pico criado:</p>"},{"location":"#criando-um-alarme-no-cloudwatch","title":"Criando um alarme no Cloudwatch","text":"<p>J\u00e1 conseguimos ent\u00e3o ter uma fun\u00e7\u00e3o Lambda que \u00e9 engatilhada a cada novo objeto colocado em um bucket e um t\u00f3pico no SNS que consegue gerar notifica\u00e7\u00f5es de email para o usu\u00e1rio cadastrado.</p> <p>Precisamos ent\u00e3o criar um componente que ir\u00e1 ser o conector entre estes, isto \u00e9, a cada vez que uma fun\u00e7\u00e3o Lambda for engatilhada, gerar uma notifica\u00e7\u00e3o para o usu\u00e1rio via SNS.</p> <p>Para isso, podemos criar um alarme no Cloudwatch que ir\u00e1 monitorar os logs padr\u00f5es gerados pela Lambda, e com isso, gera uma notifica\u00e7\u00e3o no t\u00f3pico.</p> <p>Dessa forma, devemos criar um alarme que:</p> <ul> <li>Receber\u00e1 o ARN do t\u00f3pico que ir\u00e1 gerar a notifica\u00e7\u00e3o;</li> <li>Ir\u00e1 filtrar nos logs da fun\u00e7\u00e3o Lambda desejada (aqui por padr\u00e3o chamada de events);</li> <li>Criar um alarme no Cloudwatch que ir\u00e1 transicionar do estado OK para ALARM a cada novo log ir\u00e1 tomar a a\u00e7\u00e3o de criar uma notifica\u00e7\u00e3o no t\u00f3pico que o ARN for passado ao template.</li> </ul> <p>Crie um arquivo chamado cloudwatch.tf em uma pasta chamada cloudwatch/ dentro do diret\u00f3rio terraform/:</p> <pre><code>mkdir cloudwatch\n</code></pre> <p>Coloque o arquivo da seguinte maneira:</p> <p>cloudwatch.tf<pre><code>variable \"sns_arn\" {\ntype = string\n}\nresource \"aws_cloudwatch_log_metric_filter\" \"lambda_log_filter\" {\nname           = \"lambda-log-filter\"\npattern        = \"{ $.eventType = Error }\" # Substitua pelo padr\u00e3o que voc\u00ea deseja monitorar\nlog_group_name = \"/aws/lambda/events\"      # Substitua pelo nome do grupo de log correto\nmetric_transformation {\nname        = \"ErrorCount\"\nnamespace   = \"Custom/CloudWatchLogs\"\nvalue       = \"1\"\ndefault_value = \"0\"\n}\n}\nresource \"aws_cloudwatch_metric_alarm\" \"lambda_log_alarm\" {\nalarm_name          = \"lambda-log-alarm\"\nalarm_description   = \"Alarm triggered on CloudWatch Logs\"\ncomparison_operator = \"GreaterThanOrEqualToThreshold\"\nevaluation_periods  = \"1\"\nmetric_name         = \"ErrorCount\"\nnamespace           = \"Custom/CloudWatchLogs\"\nperiod              = \"60\"\nstatistic           = \"SampleCount\"\nthreshold           = \"1\"\nalarm_actions       = [var.sns_arn]\ntreat_missing_data  = \"missing\"\n}\nresource \"aws_cloudwatch_log_metric_filter\" \"lambda_log_filter_subscription\" {\nname           = \"lambda-log-filter-subscription\"\npattern        = \"{ $.eventType = Error }\" # Substitua pelo padr\u00e3o que voc\u00ea deseja monitorar\nlog_group_name = \"/aws/lambda/events\"      # Substitua pelo nome do grupo de log correto\nmetric_transformation {\nname      = \"ErrorCountSubscription\"\nnamespace = \"Custom/CloudWatchLogs\"\nvalue     = \"1\"\n}\n}\n</code></pre> Dessa forma sua organiza\u00e7\u00e3o de diret\u00f3rio deve ficar assim:</p> <pre><code>terraform/\n  |\n  ------main.tf\n  |\n  ------lambda/\n      |\n      ------lambda.tf\n  |\n  ------sns/\n      |\n      ------sns.tf\n  |\n  ------s3/\n      |\n      ------s3.tf\n  |\n  ------s3_website/\n      |\n      ------s3_website.tf\n  |\n  ------cloudwatch/\n    |\n    ------cloudwatch.tf\n</code></pre> <p>Modifique o arquivo main.tf, para adequar o m\u00f3dulo rec\u00e9m criado:</p> <p>Veja que passamos o ARN do t\u00f3pico do SNS criado como uma vari\u00e1vel para o Cloudwatch Alarme.</p> main.tf<pre><code>provider \"aws\" {\nregion     = \"us-east-1\"\n}\nmodule \"lambda\" {\nsource = \"./lambda\"\n}\noutput \"function_name\" {\nvalue = module.lambda.function_name\n}\noutput \"function_arn\" {\nvalue = module.lambda.function_arn\n}\nmodule \"s3\" {\nsource = \"./s3\"\nfunction_name = module.lambda.function_name\nfunction_arn = module.lambda.function_arn\n}\nmodule \"website\" {\nsource = \"./s3_website\"\n}\nmodule \"sns\" {\nsource = \"./sns\"\n}\noutput \"sns_arn\" {\nvalue = module.sns.sns_arn\n}\nmodule \"cloudwatch\" {\nsource = \"./cloudwatch\"\nsns_arn = module.sns.sns_arn\n}\n</code></pre> <p>Rode em seu terminal para iniciar novamente o backend:</p> <pre><code>terraform init\n</code></pre> <p>Veja se o acoplamento l\u00f3gico dos componentes est\u00e1 correto:</p> <pre><code>terraform plan\n</code></pre> <p>Aplique as mudan\u00e7as:</p> <p><pre><code>terraform apply -auto-approve\n</code></pre> Estando tudo correto, voc\u00ea dever\u00e1 em seu console, o alarme do Cloudwatch criado:</p> <p>Veja em seu email cadastrado que voc\u00ea deve ter recebido uma notifica\u00e7\u00e3o:</p> <p>Para testar o funcionamento da arquitetura, adicione um objeto qualquer ao Bucket S3 rec\u00e9m criado. Depois de alguns minutos voc\u00ea dever\u00e1 receber um email como o abaixo, indicando que o Alarme do CloudWatch Alarme foi acionado e um novo objeto foi adicionado no bucket.</p> <p>Cloudwatch notificando alarme:</p> <p>Email de notifica\u00e7\u00e3o:</p>"}]}